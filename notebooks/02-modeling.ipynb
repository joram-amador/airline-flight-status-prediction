{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2529375",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64f0e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 150)\n",
    "pd.set_option(\"display.max_rows\", 150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddf94d1",
   "metadata": {},
   "source": [
    "# 1. Load Data & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7f2e36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"../data\")\n",
    "df = pd.read_csv(data_dir / \"Airline Dataset Updated - v2.csv\")\n",
    "\n",
    "# confirm data loaded\n",
    "df.head()\n",
    "\n",
    "# Seperate Target and Predictors\n",
    "y = df[\"Flight Status\"]\n",
    "X = df.drop([\"Flight Status\"], axis=1)\n",
    "\n",
    "# Train / Test Split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, train_size=0.8, \n",
    "    test_size=0.2, random_state=0, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20ecf5c",
   "metadata": {},
   "source": [
    "# 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40e4bc99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train cols: Index(['Gender', 'Age', 'Nationality', 'Country Name', 'Airport Continent',\n",
      "       'Continents', 'Departure Date'],\n",
      "      dtype='object')\n",
      "X_valid cols: Index(['Gender', 'Age', 'Nationality', 'Country Name', 'Airport Continent',\n",
      "       'Continents', 'Departure Date'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Preprocess X_train and X_valid:\n",
    "# - Drop unhelpful IDs for prediction\n",
    "# - Extract month \n",
    "\n",
    "# Drop IDs\n",
    "X_train = X_train.drop(columns=[\"Passenger ID\", \"First Name\", \"Last Name\", \"Pilot Name\"])\n",
    "X_valid = X_valid.drop(columns=[\"Passenger ID\", \"First Name\", \"Last Name\", \"Pilot Name\"])\n",
    "\n",
    "\n",
    "# Drop Airport Name and Arrival Airport since most categories have less than 20 entries\n",
    "X_train = X_train.drop(columns=[\"Airport Name\", \"Arrival Airport\", \"Airport Country Code\"])\n",
    "X_valid = X_valid.drop(columns=[\"Airport Name\", \"Arrival Airport\", \"Airport Country Code\"])\n",
    "print(f\"X_train cols: {X_train.columns}\")\n",
    "print(f\"X_valid cols: {X_valid.columns}\")\n",
    "\n",
    "# Extract Month\n",
    "parsed_train = pd.to_datetime(X_train[\"Departure Date\"], format=\"mixed\", errors=\"coerce\")\n",
    "\n",
    "train_month = parsed_train.dt.month\n",
    "X_train[\"Month\"] = train_month\n",
    "X_train = X_train.drop(columns=[\"Departure Date\"])\n",
    "\n",
    "parsed_valid = pd.to_datetime(X_valid[\"Departure Date\"],\n",
    "format=\"mixed\", errors=\"coerce\")\n",
    "\n",
    "valid_month = parsed_valid.dt.month\n",
    "X_valid[\"Month\"] = valid_month\n",
    "X_valid = X_valid.drop(columns=[\"Departure Date\"])\n",
    "\n",
    "X_train.head()\n",
    "X_valid.head()\n",
    "\n",
    "numerical_cols = [\"Age\"]\n",
    "categorical_cols = [\"Gender\", \"Nationality\", \"Country Name\",\n",
    "\"Continents\", \"Month\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07bcc05",
   "metadata": {},
   "source": [
    "# 3. Baseline Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f2a0ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticReg\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Constructing Pipeline\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle the preprocessing\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5e45783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define Model\n",
    "base_model = LogisticRegression(max_iter=5000, random_state=0)\n",
    "\n",
    "# Bundle preprocessing and model into pipeline\n",
    "base_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('model', base_model)])\n",
    "\n",
    "# Fit model and get predictions\n",
    "base_pipeline.fit(X_train, y_train)\n",
    "base_preds = base_pipeline.predict(X_valid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d030f2cd",
   "metadata": {},
   "source": [
    "# 4. RandomForest Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65771efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "forest_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                  ('model', forest_model)])\n",
    "\n",
    "# Fit model and get predictions\n",
    "forest_pipeline.fit(X_train, y_train)\n",
    "forest_preds = forest_pipeline.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ac7a41",
   "metadata": {},
   "source": [
    "# 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af685943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (LogisticRegression) model validation accuracy: 0.3338065301155952\n",
      "RandomForest model validation accuracy: 0.32893936321233014\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Logistic Regression model\n",
    "base_acc = accuracy_score(y_valid, base_preds)\n",
    "print(f\"Baseline (LogisticRegression) model validation accuracy: {base_acc}\")\n",
    "\n",
    "\n",
    "# Evaluate RandomForest Model\n",
    "forest_acc = accuracy_score(y_valid, forest_preds)\n",
    "print(f\"RandomForest model validation accuracy: {forest_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b618a",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Both Logistic Regression (~33%) and Random Forest Classifier (~32%) models had a validation accuracy comparable to random guessing between the three categories of flight status. This result lines up with obeservations made during EDA where proportions of the flight status remained about the same throughout individual features and interactions.\n",
    "\n",
    "EDA had hinted that the features were not strong predictors of the flight status since there was little variance of the target when looking at distributions. Thus, the given features have limited predictive information as shown by the modeling results.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
